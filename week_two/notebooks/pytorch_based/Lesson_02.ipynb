{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTlIsON_7_d8"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from IPython import display\n",
        "from IPython.display import YouTubeVideo"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lakota AI Code Camp Lesson 02: Introduction to Image Recognition"
      ],
      "metadata": {
        "id": "iFZni6pC8Fid"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## History\n",
        "\n",
        "Image recognition was at the heart of the the current neural network revolution.\n",
        "There were roughly three fundamental requirements for human-level performance to occur:\n",
        "\n",
        "1.   a large dataset;\n",
        "1.   convolutional layers;\n",
        "1.   computational power required for multiple layers.\n",
        "\n",
        "The convolutional layer has its origin in the work of Dr. Kunihiko Fukushima, a Japanese scientist.\n",
        "He was inspired by a paper about the vision of cats.\n",
        "This led him to develop an early version of the convolutional neural network with his Neocognitron algorithm.\n",
        "\n",
        "<img src=\"https://www.fi.edu/sites/default/files/2021-08/Kunihiko_Fukushima.jpg\" alt=\"Kunihiko Fukushima\" width=\"250\" height=\"250\">\n",
        "\n",
        "[The Franklin Institute profile of Kunihiko Fukushima](https://www.fi.edu/en/laureates/kunihiko-fukushima)\n",
        "\n",
        "After this, the convolutional layer was further popularized by Dr. Yann LeCun's and partner's 1989 work, called LeNet, after LeCun.\n",
        "One of the primary innovations of this paper was the usage of backpropagation (more on this later in the course) to convolutional neural networks.\n",
        "\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/2/22/Yann_LeCun_-_2018_%28cropped%29.jpg/800px-Yann_LeCun_-_2018_%28cropped%29.jpg\" alt=\"Yann Lecun\" width=\"324\" height=\"373\">\n",
        "\n",
        "[Conference of French computer scientist Yann LeCun, director of Facebook AI Research, at the École Polytechnique By Jérémy Barande / Ecole polytechnique Université Paris-Saclay, CC BY-SA 2.0](https://commons.wikimedia.org/w/index.php?curid=72169777)\n",
        "\n",
        "The large dataset's inception was in 2007.\n",
        "Dr. Fei-Fei Li began her work on ImageNet, a comprehensive dataset consisting of millions of images\n",
        "categorized by the subject of the image.\n",
        "At the time, it was the largest image dataset of its kind.\n",
        "\n",
        "The dataset became part of the ImageNet Large Scale Visual Recognition Challenge (LSVRC), starting in 2010.\n",
        "The task was:\n",
        "\n",
        "*   given 10,000,000+ images classified into 10,000+ categories\n",
        "*   classify 200,000 images into 1,000 object categories.\n",
        "\n",
        "It is still in common usage as a neural network training dataset today.\n",
        "\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/c/c7/Fei-Fei_Li_at_AI_for_Good_2017.jpg/800px-Fei-Fei_Li_at_AI_for_Good_2017.jpg\" alt=\"Fei-Fei Li speaking at AI for Good 2017\" width=\"227\" height=\"338\">\n",
        "\n",
        "[By ITU Pictures - https://www.flickr.com/photos/itupictures/35011409612/, CC BY 2.0](https://commons.wikimedia.org/w/index.php?curid=69625478)\n",
        "\n",
        "In 2012, Alex Krizhevsky, Dr. Ilya Sutskever, and Dr. Geoffrey Hinton developed **AlexNet**, a deep neural\n",
        "network.\n",
        "Although it only had 3 more layers than LeNet, it had roughly 3,500x more parameters (we'll talk more about this later, but it's a rough method for determining the complexity of the neural network).\n",
        "LeNet had about 14,596 parameters (the actual implementation is slightly more complicated, due to weight sharing and has 9,760 parameters), whereas AlexNet had 50,844,008 parameters.\n",
        "Even thought it only had 14,596 parameters, LeNet required 3 days of training.\n",
        "In contrast, AlexNet took 5-6 days on a computer with 2 GPUs.\n",
        "\n",
        "<img src=\"https://i.kinja-img.com/gawker-media/image/upload/c_fit,f_auto,g_center,q_60,w_1600/359da54f0801154b7db8c74420d368bf.jpg\" alt=\"Alex Krizhevsky\" width=\"400\" height=\"225\">\n",
        "\n",
        "[The inside story of how AI got good enough to dominate Silicon Valley](https://qz.com/1307091/the-inside-story-of-how-ai-got-good-enough-to-dominate-silicon-valley)\n",
        "\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/3/34/Geoffrey_Hinton_at_UBC.jpg/800px-Geoffrey_Hinton_at_UBC.jpg\" alt=\"Geoffrey Hinton\" width=\"292\" height=\"390\">\n",
        "\n",
        "[Geoffrey Hinton giving a lecture about deep neural networks at the University of British Columbia By Eviatar Bach - Own work, CC BY-SA 3.0](https://commons.wikimedia.org/w/index.php?curid=26477087)\n"
      ],
      "metadata": {
        "id": "Oe-9108Tud5T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're going to go through a version of LeNet.\n",
        "We're going to train a version of LeNet on an image dataset called CIFAR 10 (CIFAR stands for Canadian Institute for Advanced Research).\n",
        "CIFAR 10 consists of 60,000 color images with a resolution of 32 x 32.\n",
        "There are 50,000 training images and 10,000 test images.\n",
        "The classes are:\n",
        "\n",
        "1.   airplane;\n",
        "1.   automobile;\n",
        "1.   bird;\n",
        "1.   cat;\n",
        "1.   deer;\n",
        "1.   dog;\n",
        "1.   frog;\n",
        "1.   horse;\n",
        "1.   ship;\n",
        "1.   truck.\n"
      ],
      "metadata": {
        "id": "JNK14kYYcsaX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're going to instantiate a tuple of strings that represent the classes above."
      ],
      "metadata": {
        "id": "pNAp50PIdiqx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_list = ('airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "id": "uTOVOTBr8DJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're going to instantiate an object that will allow give us an image with its label.\n",
        "This first call is so that we can normalize our dataset."
      ],
      "metadata": {
        "id": "UC0r1mwwdqRA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "normalize_ds = torchvision.datasets.CIFAR10(root='./data',\n",
        "                                            train=True,\n",
        "                                            download=True,\n",
        "                                            transform=torchvision.transforms.ToTensor(),\n",
        "                                            )\n",
        "normalize_dl = torch.utils.data.DataLoader(normalize_ds,\n",
        "                                           batch_size=len(normalize_ds),\n",
        "                                           shuffle=True,\n",
        "                                           num_workers=0)"
      ],
      "metadata": {
        "id": "Rli8FuSkdcgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're going to normalize the data."
      ],
      "metadata": {
        "id": "OOLzpOdpd1Yh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for data, _ in normalize_dl:\n",
        "    mean = torch.mean(data, (0, 2, 3))\n",
        "    std = torch.std(data, (0, 2, 3))"
      ],
      "metadata": {
        "id": "7MUvuLLVdgS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This just converts our data into a format that our model can use and normalizes it."
      ],
      "metadata": {
        "id": "6goG6d8Vd4Pv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = torchvision.transforms.Compose(\n",
        "    [torchvision.transforms.ToTensor(),\n",
        "     torchvision.transforms.Normalize(mean=mean, std=std),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "B6lP5-Zvd645"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We actually call our dataset."
      ],
      "metadata": {
        "id": "AgHqgUltd6hN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = torchvision.datasets.CIFAR10(root='./data', train=True, transform=transform)\n",
        "test_ds = torchvision.datasets.CIFAR10(root='./data', train=False, transform=transform)"
      ],
      "metadata": {
        "id": "iqWfc7I4eMT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "We create a class for our model LeNet."
      ],
      "metadata": {
        "id": "uCUg0WhteL_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LeNet(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = torch.nn.Conv2d(in_channels=3,\n",
        "                                     out_channels=6,\n",
        "                                     kernel_size=5,\n",
        "                                     padding=2)\n",
        "        self.conv2 = torch.nn.Conv2d(in_channels=6,\n",
        "                                     out_channels=16,\n",
        "                                     kernel_size=5)\n",
        "        self.pool = torch.nn.AvgPool2d(kernel_size=2,\n",
        "                                       stride=2)\n",
        "        self.fc1 = torch.nn.Linear(in_features=576,\n",
        "                                   out_features=120)\n",
        "        self.fc2 = torch.nn.Linear(in_features=120,\n",
        "                                   out_features=84)\n",
        "        self.fc3 = torch.nn.Linear(in_features=84,\n",
        "                                   out_features=10)\n",
        "        self.activation = torch.tanh\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.pool(x)\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.activation(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "Mb-i7MlBeTFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We instantiate it."
      ],
      "metadata": {
        "id": "YpKQ6SYleTz_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LeNet()"
      ],
      "metadata": {
        "id": "E1AiVNnReV_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We create a helper function that will show us images from our dataset."
      ],
      "metadata": {
        "id": "IgBQ6trfeY45"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def imshow(img, label=None, class_list=class_list):\n",
        "    # Pytorch has images in Channel x height x width, this converts to h x w x c\n",
        "    img = img.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.4914, 0.4822, 0.4465])\n",
        "    std = np.array([0.2470, 0.2435, 0.2616])\n",
        "    # undo the normalization\n",
        "    img = std * img + mean\n",
        "    # ensure that array is in the proper range to show the image.\n",
        "    img = np.clip(img, 0, 1)\n",
        "    plt.imshow(img)\n",
        "    if label is not None:\n",
        "        # label is assumed to be a (1, ) tensor\n",
        "        label = label.item()\n",
        "        label = class_list[label]\n",
        "        plt.title(label)\n",
        "    plt.pause(0.001)"
      ],
      "metadata": {
        "id": "Y_piidwTecFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We get an image from our training dataset."
      ],
      "metadata": {
        "id": "OMIuYyjPeh1T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images, classes = next(iter(train_loader))"
      ],
      "metadata": {
        "id": "xNmdVX29eekB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the shape of our tensor (we'll go into this more later)."
      ],
      "metadata": {
        "id": "YXNDHuXgef0i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images.shape"
      ],
      "metadata": {
        "id": "NMGp6k4UefX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We call a random image and its label."
      ],
      "metadata": {
        "id": "f6tAB4K1ecx3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num = random.randint(0, 49_999)\n",
        "imshow(images[num], classes[num])"
      ],
      "metadata": {
        "id": "oeVDhzxsevn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We make a helper function that takes in a model, an image, and a list of the classes and gives us a prediction."
      ],
      "metadata": {
        "id": "6VDjOA3TevNB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_prediction(model, image, class_list=class_list):\n",
        "    # If shape is not\n",
        "    image = image.unsqueeze(0)\n",
        "    pred = model(image)\n",
        "    pred = torch.argmax(pred)\n",
        "    return class_list[pred]"
      ],
      "metadata": {
        "id": "46h2SRwefIZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our model isn't trained, so it should give us an incorrect prediction"
      ],
      "metadata": {
        "id": "RSeNMEN8fKb9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "make_prediction(model, images[num])"
      ],
      "metadata": {
        "id": "1RIQno7afQtP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We make a training function."
      ],
      "metadata": {
        "id": "PFh9PsrcfUG0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, criterion, opt, epochs=10):\n",
        "    history = []\n",
        "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "    model.to(device)\n",
        "\n",
        "    print(\"Epoch | Batch | Time(s) | Loss\")\n",
        "    print(\"------------------------------\")\n",
        "\n",
        "    step = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        t = time.time()\n",
        "\n",
        "        for i, (inputs, label) in enumerate(train_loader, 0):\n",
        "            inputs, label = inputs.to(device), label.to(device)\n",
        "\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, label)\n",
        "\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            step += 1\n",
        "            history.append((step, loss))\n",
        "\n",
        "        t = time.time() - t\n",
        "        print(f\"{epoch + 1:5d} | {i:5d} | {int(t):8d} | {running_loss:.5f}\")\n",
        "        running_loss = 0\n",
        "\n",
        "    return history"
      ],
      "metadata": {
        "id": "JPwA8DcufThe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We  make an evaluation function."
      ],
      "metadata": {
        "id": "9fKlzZAxfZMi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, testloader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, label in test_loader:\n",
        "            inputs, label = inputs.to(device), label.to(device)\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += label.size(0)\n",
        "            correct += (predicted == label).sum().item()\n",
        "\n",
        "    print(f'Accuracy of the network on 10000 test images: {100 * correct // total} %')\n",
        "    return 100 * correct // total"
      ],
      "metadata": {
        "id": "adNdAtIWfcfu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We send our model to the GPU if its available, otherwise it goes to the CPU."
      ],
      "metadata": {
        "id": "ktXbGtqufeby"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "opt = torch.optim.SGD(model.parameters(), lr=1e-1, momentum=0.9)"
      ],
      "metadata": {
        "id": "zd6JrmjKfglY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We evaluate before training."
      ],
      "metadata": {
        "id": "ltJWZFv5flFM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(model, test_loader)"
      ],
      "metadata": {
        "id": "v5uiWU9ifnA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We train the model."
      ],
      "metadata": {
        "id": "5INorcVDfpIU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = train(model, train_loader, criterion, opt, epochs=100)"
      ],
      "metadata": {
        "id": "A5FMhvFQfqok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll look at the plot of the loss (we'll learn more about this later) versus the number of epochs our model was trained for."
      ],
      "metadata": {
        "id": "lrgGAgRBfvlG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_steps = np.array([step for step, _ in history])\n",
        "loss = np.array([loss.item() for _, loss in history])\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(training_steps, loss)\n",
        "\n",
        "ax.set(xlabel='training_steps', ylabel='loss')\n",
        "ax.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gFMsa06afvO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We evaluate the model."
      ],
      "metadata": {
        "id": "6u6yQDOLf7Du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(model, test_loader)"
      ],
      "metadata": {
        "id": "4NO5_Gngf8vS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num = random.randint(0, 49_999)\n",
        "imshow(images[num], classes[num])"
      ],
      "metadata": {
        "id": "38SrxpDbf-OD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(make_prediction(model, images[9].to(device)), class_list[classes[num]])"
      ],
      "metadata": {
        "id": "AKF1SRAagKgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great! Next, we're going to go into an introduction on Object Detection.\n"
      ],
      "metadata": {
        "id": "_hN6jTeagQh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## References\n",
        "\n"
      ],
      "metadata": {
        "id": "hfC46o2WUiqf"
      }
    }
  ]
}