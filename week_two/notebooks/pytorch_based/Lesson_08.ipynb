{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-K2Gx4qQkFpN"
      },
      "outputs": [],
      "source": [
        "import pprint\n",
        "import requests\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from io import BytesIO\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lakota AI Code Camp Lesson 08: Matrix Algebra IV\n",
        "\n",
        "## Matrix Multiplication\n",
        "\n",
        "An important concept in mathematics and computer science is composition.\n",
        "Recall that a function takes an input and gives an output.\n",
        "So, if we compose two functions, say $f$ and $g$, denoted by $f \\circ g (x) = f(g(x))$, then the input of $f$ is the output of $g$.\n",
        "\n",
        "Often, we want to compose two linear transformations.\n",
        "If $\\textbf{A} = (a_{ij})_{ij}$ is a matrix for the linear transformation $T$ and $\\textbf{B} = (b_{ij})_{ij}$ is a matrix for the linear transformation $S$, then $T(S(\\textbf{v}))$ corresponds to the vector\n",
        "$$\n",
        "\\left(\n",
        "    \\sum_{j=1}^{n} \\sum_{k = 1}^{m} a_{ik}b_{kj} v_{j}\n",
        "\\right)_{i}\n",
        "$$\n",
        "\n",
        "The matrix corresponding to the linear transformation $T\\circ S$ is\n",
        "$$\n",
        "\\left(\n",
        "    \\sum_{k = 1}^{m} a_{ik}b_{kj}\n",
        "\\right)_{ij} = \\textbf{A} \\cdot \\textbf{B}.\n",
        "$$\n",
        "Another way to think about it is that matrix multiplication comes from the dot products of the rows of the first matrix with the columns of the second matrix.\n",
        "The dot product method is why we implemented the transpose method of the `Matrix` class.\n",
        "\n",
        "We can also do matrix multiplication with a series of matrix vector operations.\n",
        "The columns of the new matrix come from the multiplication of the matrix $\\textbf{A}$ with the column vectors.\n",
        "\n",
        "So, you have a number of different ways to think about and implement matrix multiplication!"
      ],
      "metadata": {
        "id": "kCMFsrYqkNFw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Vector():\n",
        "\n",
        "    def __init__(self, values):\n",
        "        # This should have an input.\n",
        "        # What do we need to input to create a vector?\n",
        "        self.values = tuple(values)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.values[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "\n",
        "        length = 0\n",
        "        for val in self.values:\n",
        "            length += 1\n",
        "        return length\n",
        "\n",
        "    def __add__(self, other):\n",
        "        if self.__len__() != other.__len__():\n",
        "            raise Exception(f\"Dimension mismatch: {self.__len__()} != {other.__len__}\")\n",
        "\n",
        "        add = []\n",
        "        for x, y in zip(self.values, other.values):\n",
        "            add.append(x + y)\n",
        "        return Vector(add)\n",
        "\n",
        "    def __sub__(self, other):\n",
        "        if self.__len__() != other.__len__():\n",
        "            raise Exception(f\"Dimension mismatch: {self.__len__()} != {other.__len__}\")\n",
        "\n",
        "        sub = []\n",
        "        for x, y in zip(self.values, other.values):\n",
        "            sub.append(x - y)\n",
        "        return Vector(sub)\n",
        "\n",
        "    def __mul__(self, scalar):\n",
        "        if type(scalar) not in [int, float]:\n",
        "            raise Exception(f\"{scalar} is not an integer or a float\")\n",
        "\n",
        "        mul = []\n",
        "        for val in self.values:\n",
        "            mul.append(val * scalar)\n",
        "        return Vector(mul)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"Vector({self.values})\"\n",
        "\n",
        "    def __str__(self):\n",
        "        vec_string = ''\n",
        "        for idx in range(self.__len__()):\n",
        "            vec_string = vec_string + str(self[idx]) + ', '\n",
        "        vec_string = \"(\" + vec_string[:-2] + \")\"\n",
        "        return \"Vector\" + vec_string"
      ],
      "metadata": {
        "id": "_B9QvNKdkMqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Matrix():\n",
        "\n",
        "    def __init__(self, values):\n",
        "        r\"\"\"\n",
        "        Args:\n",
        "            values (list of lists): A list of n (rows) lists.\n",
        "                The n lists all have the same length m (columns).\n",
        "        \"\"\"\n",
        "        self.rows = len(values)\n",
        "        self.cols = len(values[0])\n",
        "        self.shape = (self.rows, self.cols)\n",
        "        self.values = self._create_matrix(values)\n",
        "\n",
        "    def _create_matrix(self, values):\n",
        "\n",
        "        for num in range(self.rows):\n",
        "            if len(values[num]) != self.cols:\n",
        "                raise Exception(f\"Dimension mismatch: {len(num)} != {self.cols}\")\n",
        "\n",
        "        for num in range(self.rows):\n",
        "            values[num] = list(values[num])\n",
        "\n",
        "        return list(values)\n",
        "\n",
        "    def __repr__(self):\n",
        "        # This needs to return a string that tells you the class and some values.\n",
        "        # Another way to think about it is that you need to give someone the right amount of\n",
        "        # information to understand this class.\n",
        "        return f\"Matrix({self.values})\"\n",
        "\n",
        "    def __getitem__(self, i, j=None):\n",
        "        # i is the row you want to access and j is the column you want to access.\n",
        "        # Reference the vector class above.\n",
        "        return self.values[i][j] if j else self.values[i]\n",
        "\n",
        "    def __len__(self):\n",
        "        # This should return an integer.\n",
        "        return self.rows\n",
        "\n",
        "    def __str__(self):\n",
        "        # This should return a string that makes the elements easy to read.\n",
        "        matrix_string = '['\n",
        "        for rows in range(self.rows):\n",
        "            matrix_string += '['\n",
        "            for cols in range(self.cols):\n",
        "                matrix_string += str(self.values[rows][cols]) + ', '\n",
        "            matrix_string = matrix_string[:-2] + ']\\n '\n",
        "        matrix_string = matrix_string[:-2] + ']'\n",
        "        return matrix_string\n",
        "\n",
        "    def transpose(self):\n",
        "        # Initialize\n",
        "        transpose = [[0 for i in range(self.rows)] for i in range(self.cols)]\n",
        "\n",
        "        # Set the values\n",
        "        for row in range(self.rows):\n",
        "            for col in range(self.cols):\n",
        "                transpose[col][row] = self.values[row][col]\n",
        "\n",
        "        return Matrix(transpose)\n",
        "\n",
        "    def __add__(self, other):\n",
        "        if not(self.rows == other.rows and self.cols == other.cols):\n",
        "            raise Exception(\"The rows or columns do not match.\")\n",
        "\n",
        "        add = [[None for i in range(self.cols)] for j in range(self.rows)]\n",
        "\n",
        "        for row in range(self.rows):\n",
        "            for col in range(self.cols):\n",
        "                add[row][col] = self.values[row][col] + other.values[row][col]\n",
        "\n",
        "        return Matrix(add)\n",
        "\n",
        "    def __sub__(self, other):\n",
        "        if not(self.rows == other.rows and self.cols == other.cols):\n",
        "            raise Exception(\"The rows or columns do not match.\")\n",
        "\n",
        "        sub = [[None for i in range(self.cols)] for j in range(self.rows)]\n",
        "\n",
        "        for row in range(self.rows):\n",
        "            for col in range(self.cols):\n",
        "                sub[row][col] = self.values[row][col] - other.values[row][col]\n",
        "\n",
        "        return Matrix(sub)"
      ],
      "metadata": {
        "id": "3L3lOWHOkcOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dot_product(vector1, vector2):\n",
        "    # We need to initialize a value\n",
        "    dot = 0\n",
        "\n",
        "    # We need to do a for loop\n",
        "    for num in range(len(vector1)):\n",
        "        dot += vector1[num] * vector2[num]\n",
        "\n",
        "    return dot"
      ],
      "metadata": {
        "id": "2hXXPNT2kfDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mat_vec_mul(matrix, vector):\n",
        "    # Our input is a matrix and a vector\n",
        "    # Our output is a vector\n",
        "    out = [0 for i in range(matrix.rows)]\n",
        "\n",
        "    for row in range(matrix.rows):\n",
        "        out[row] = dot_product(Vector(matrix[row]), vector)\n",
        "\n",
        "#        for col in range(matrix.cols):\n",
        "#            out[row] += matrix[row][col] * vector[col]\n",
        "\n",
        "    return Vector(out)"
      ],
      "metadata": {
        "id": "ynjarMd8kgL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def matrix_mult(matrix1, matrix2):\n",
        "    # The inputs are two matrices.\n",
        "    # The output is a matrix.\n",
        "    if matrix1.cols != matrix2.rows:\n",
        "        raise Exception(f\"Dimension mismatch! Rows should equal columns, but {matrix1.cols} != {matrix2.rows}\")\n",
        "\n",
        "    out = [[0 for i in range(matrix2.cols)] for j in range(matrix1.rows)]\n",
        "\n",
        "    for row in range(matrix1.rows):\n",
        "        for col in range(matrix2.cols):\n",
        "            for k in range(matrix1.cols):\n",
        "                out[row][col] += matrix1[row][k] * matrix2[k][col]\n",
        "\n",
        "    return Matrix(out)"
      ],
      "metadata": {
        "id": "mzHzSa2OkiYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A = Matrix([[1, 2, 3], [4, 5, 6]])\n",
        "B = Matrix([[1, 2], [3, 4], [5, 6]])\n",
        "\n",
        "C = matrix_mult(A, B)\n",
        "print(C)"
      ],
      "metadata": {
        "id": "rulLZL6Xkkio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're going to talk about the numpy and pytorch libraries and if we have time, we're going to go back to the BLAS functions!\n",
        "\n",
        "The numpy `ndarray` class and the pytorch `Tensor` class operate similarly.\n",
        "We're going to just call these tensors from now on.\n",
        "How we can think of these is that they are an array of an array of an array of arrays, etc.\n",
        "So, a vector is an array of numbers.\n",
        "A matrix is an array of an array of numbers.\n",
        "We can have an array of matrices, which is an array of an array of an array of numbers.\n",
        "We can keep going.\n",
        "\n",
        "The **shape** of a tensor is the length of each array.\n",
        "For an $n$-dimensional vector, it has shape  $(n, )$.\n",
        "For an $n \\times m$ matrix, it has shape $(n, m)$.\n",
        "For a collection of $p$ different $n \\times m$ matrices, the collection would have shape $(p, n, m)$.\n",
        "\n",
        "The primary example we're going to have is images.\n",
        "A black and white image can be represented by a matrix, where the values of the matrix corresponds to the intensity of the light.\n",
        "So, if we had an image of height 224 pixels and width 224 pixels, the matrix would have shape $(224, 224)$.\n",
        "Typically, the height is the number of rows and the width is the number of columns in the matrix.\n",
        "\n",
        "A color image can be represented by 3 matrices; this corresponds to the different color channels **rgb**, which stands for red green blue.\n",
        "There is a matrix that corresponds to the red values, a matrix that corresponds to the blue values, and a matrix that corresponds to the green values.\n",
        "Each of these matrices would have shape $(224, 224)$ and the collection of the matrices would have shape $(3, 224, 224)$.\n",
        "Typically, we call the number 3 above the channels.\n",
        "You should note that different storage systems have the channel in different places.\n",
        "\n",
        "If we have a collection of color images, say 16, then that could be represented as a tensor of shape $(16, 3, 224, 224)$.\n",
        "\n",
        "There are several ways to make an `ndarray` or `tensor`."
      ],
      "metadata": {
        "id": "sfMURJils9cf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([[1, 2, 3], [4, 5, 6]])"
      ],
      "metadata": {
        "id": "34zgQAZcvBbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBMuO9Qi1t-H",
        "outputId": "c35a401d-d403-4159-a5b9-728f9906e0b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 2, 3],\n",
              "       [4, 5, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_tensor = torch.tensor([[1, 2, 3], [4, 5, 6]])"
      ],
      "metadata": {
        "id": "1Ec2pnXp1vt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDqwTqIc1ynp",
        "outputId": "bceea9de-c439-4712-e121-662d4b30da98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [4, 5, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_tensor = torch.tensor(x)"
      ],
      "metadata": {
        "id": "IdB6UawF1zxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GH0ehH7F10sS",
        "outputId": "6a2e9b9a-48a0-4ec2-8b24-96c7896fcc6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [4, 5, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_numpy = x_tensor.numpy()"
      ],
      "metadata": {
        "id": "61R1bPaq113U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIqrqHs1128M",
        "outputId": "de558f12-be27-4feb-ab77-ab3c688637a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 2, 3],\n",
              "       [4, 5, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can get the shape from the `ndarray` and `tensor` by:"
      ],
      "metadata": {
        "id": "U9Jnoq9h152x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_numpy.shape)\n",
        "print(x_tensor.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brPL7I4m14UF",
        "outputId": "d44194e3-5759-40cb-8e3d-6ca38558c3aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 3)\n",
            "torch.Size([2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "An important fact to know is that all `ndarrays` and `tensors` are stored as flat arrays.\n",
        "That is, they're stored as arrays of shape $(n, )$.\n",
        "If we have a `tensor` of shape $(16, 3, 224, 224)$, then it's stored as a **flat** array of $16 \\times 3 \\times 224 \\times 224 = 2,408,448$ values.\n",
        "How the `ndarray` and `tensor` transforms this data is by what are called **strides**.\n",
        "The stride tells us how to skip over the data."
      ],
      "metadata": {
        "id": "9bFZj7KQD-la"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_numpy.strides"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxG19VVk19y5",
        "outputId": "a9a26f5e-b555-4197-b52e-5d1fd48ddc3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The layout of `x_numpy` is $[1, 2, 3, 4, 5, 6]$.\n",
        "Each of these values in the array occupy 8 bytes.\n",
        "If we want to get element $4$, we would have to go $24 + 8$ bytes into our array.\n",
        "\n",
        "It should be noted that the numpy strides are based on bytes! In numpy, ints are 64 bit by default, so they cover 8 bytes."
      ],
      "metadata": {
        "id": "Av3ihVM_EZYE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "type(x_numpy[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wvh56lw4EY1u",
        "outputId": "8fa2cbc3-fac4-4867-aca6-ecffc8d35396"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I prefer the way pytorch gives us the strides.\n",
        "It abstracts away the size of our objects in memory and just treats it like an array of arrays."
      ],
      "metadata": {
        "id": "PWqNvFulEpcl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_tensor.stride()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twGu-etFEnze",
        "outputId": "82f7066a-0509-4945-db3b-72ba3ffa8ce0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The layout of `x_tensor` is the same as `x_numpy`.\n",
        "If we want to access the element in row $i$  and column $j$, we select the $3 * i + j$th element in our array.\n",
        "\n",
        "If we have a tensor of shape $(16, 3, 28, 28)$, a collection of 16 color images with height and width of 28 pixels, then the stride will be $(2352, 784,28, 1)$.\n",
        "So, if we want to access the pixel at $(5, 1, 15, 13)$, we call `images[4][0][14][12]`.\n",
        "Under the hood, the tensor is calling `images[4 * 2352 + 0 * 784 + 28 * 14 + 1 * 12]` or `images[9812]`."
      ],
      "metadata": {
        "id": "YOjX9TQeEtMY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images = torch.rand((16, 3, 28, 28))"
      ],
      "metadata": {
        "id": "LHozfl1VFAOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bpq9TgtRFXX2",
        "outputId": "7fb81570-1c08-4fce-862f-64ef4fcd887a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 3, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images.stride()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnqOS0DzFsfF",
        "outputId": "c1796000-6681-49e2-df6c-99b0dcc97401"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2352, 784, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images[4][0][14][12]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pW6Uh8VxFc4-",
        "outputId": "1a3b0afc-e753-4db1-807d-73630e2ced33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0178)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.flatten(images).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVL3aQ6vFgAB",
        "outputId": "03f3da39-0979-4c0e-856b-2c0df3ee89fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([37632])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.flatten(images)[9812]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5EvZDWzFiI_",
        "outputId": "568830d1-a167-4c9d-b078-0ce717580617"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0178)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we're going to look at how to do our operations above."
      ],
      "metadata": {
        "id": "56Pyz2J7FAsf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor1 = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "tensor2 = torch.tensor([[1, 2], [3, 4], [5, 6]])"
      ],
      "metadata": {
        "id": "1tO27UsuEslF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.matmul(tensor1, tensor2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AskoMTohF0qt",
        "outputId": "baae9dee-8783-493e-a8ac-13a7ebea2e9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[22, 28],\n",
              "        [49, 64]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we want to do matrix vector multiplication we do:"
      ],
      "metadata": {
        "id": "4ajs9d1DF3aY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "matrix = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
        "vector = torch.tensor([1, 5, 3])"
      ],
      "metadata": {
        "id": "8jgrMWYUF32v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mv(matrix, vector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoyWm-L5F6Ff",
        "outputId": "2ff21112-235d-4643-eefe-3f88f85e7a52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([20, 47, 74])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dot product is:"
      ],
      "metadata": {
        "id": "iN1ojNnLGGF5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vector1 = torch.tensor([1, 5, 3])\n",
        "vector2 = torch.tensor([2, 1, 2])"
      ],
      "metadata": {
        "id": "ehhv0GGZGEgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.dot(vector1, vector2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eblqzTgF7GV",
        "outputId": "7aa37760-2307-49f2-d90c-ee885baee22b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(13)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, one important concept to know about is broadcasting.\n",
        "Broadcasting allows us to add or multiply a matrix and a vector together or in general any `tensor` with any `tensor` as long as a few rules are followed:\n",
        "\n",
        "### Broadcasting rules\n",
        "\n",
        "These rules are determined by the shape: the rightmost elements of the shape are the same or one of them is 1, then proceeds to the left.\n",
        "\n",
        "So, we can add a $(28, )$-tensor to a $(16, 3, 28, 28)$-tensor.\n",
        "We can add a $(3, 1, 28)$-tensor to a $(16, 3, 28, 28)$-tensor.\n",
        "We can add a $(3, 28, 28)$-tensor to a $(16, 3, 28, 28)$-tensor.\n",
        "Or even a $(3, 4, 1)$-tensor to a $(3, 1, 5)$-tensor."
      ],
      "metadata": {
        "id": "rYCvssEBGJUZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = torch.rand(28)\n",
        "y = torch.rand(16, 3, 28, 28)"
      ],
      "metadata": {
        "id": "8L2MjWAHGk3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x1 + y).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ERCrxXUGl_U",
        "outputId": "4c73422a-998c-4b59-b597-c66883a9d1aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 3, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x2 = torch.rand(3, 1, 28)"
      ],
      "metadata": {
        "id": "KBGuBIJHGppc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x2 + y).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-M_da0ISGxqN",
        "outputId": "10a58164-4f58-4d6a-a9fe-251cc6aa3fe9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 3, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x3 = torch.rand(3, 28, 28)"
      ],
      "metadata": {
        "id": "T0qBDnGUG0gW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x3 + y).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPiCMnDBG4HP",
        "outputId": "ea3a4332-13d6-43b4-feda-5e0358aa5c26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 3, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z1 = torch.rand(3, 4, 1)\n",
        "z2 = torch.rand(3, 1, 5)"
      ],
      "metadata": {
        "id": "N-9-vaDjG4v9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(z1 + z2).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpQ8HmIWG75f",
        "outputId": "9ce6ff0e-d65f-4fa8-da5f-d9f9f5042fd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 4, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def is_broadcastable(shape1, shape2):\n",
        "\n",
        "    # Initialization\n",
        "    broadcast = False\n",
        "\n",
        "    # We need to only check over the smallest shape.\n",
        "    min_length = min(len(shape1), len(shape2))\n",
        "\n",
        "    # We start at the end.\n",
        "    shape1 = list(reversed(shape1))\n",
        "    shape2 = list(reversed(shape2))\n",
        "\n",
        "    # We only keep the necessary elements.\n",
        "    shape1 = shape1[:min_length]\n",
        "    shape2 = shape2[:min_length]\n",
        "\n",
        "    # zip combines shape1 and shape2\n",
        "    for x, y in zip(shape1, shape2):\n",
        "        # We check that the shapes are the same or one of them is 1.\n",
        "        if (x == y) or (x == 1) or (y == 1):\n",
        "            broadcast = True\n",
        "        else:\n",
        "            # If the above condition ever fails, the tensors are not broadcastable.\n",
        "            return False\n",
        "\n",
        "    return broadcast"
      ],
      "metadata": {
        "id": "6rz_n4uYG9TR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "is_broadcastable((8, 1, 6, 1), (7, 1, 5))"
      ],
      "metadata": {
        "id": "9F8zwQ82HAlP",
        "outputId": "df39c03f-38f4-4817-d44b-7e7579248979",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    }
  ]
}