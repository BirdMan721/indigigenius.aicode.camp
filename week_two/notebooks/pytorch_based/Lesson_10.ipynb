{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9K7RxgU4HvER"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import random\n",
        "import requests\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from io import BytesIO\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lakota AI Code Camp Lesson 10: Introduction to Neural Networks 0\n",
        "\n",
        "## XOR Problem\n",
        "\n",
        "XOR is a fundamental computer gate.\n",
        "It takes two binary inputs and outputs a binary value.\n",
        "\n",
        "|Input 1 | Input 2 | XOR Value |\n",
        "|--------|---------|-----------|\n",
        "| 1 | 1 | 0 |\n",
        "| 1 | 0 | 1 |\n",
        "| 0 | 1 | 1 |\n",
        "| 0 | 0 | 0 |\n",
        "\n",
        "In 1969, Marvin L. Minsky and Seymour A. Papert wrote a book called *Perceptrons* that looked at the XOR problem for single layer neural networks (also called a perceptron).\n",
        "What they showed was that a perceptron could not learn the XOR function."
      ],
      "metadata": {
        "id": "s_tA5UvKHxpQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're going to make a small neural network.\n",
        "It's going to have two \"neurons\" and take in a binary vector of dimension 2.\n",
        "\n",
        "First, we have to initialize our values and we do this by drawing each of our parameters from what's called a normal distribution.\n"
      ],
      "metadata": {
        "id": "KtmT9ZqETx9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = random.gauss(mu=0.0, sigma=1.0)\n",
        "b = random.gauss(mu=0.0, sigma=1.0)\n",
        "c = random.gauss(mu=0.0, sigma=1.0)"
      ],
      "metadata": {
        "id": "XELC9Sh8TxMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to determine how big our steps are in training and how long we're going to train."
      ],
      "metadata": {
        "id": "n5-hh_5XUoHr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 1000000\n",
        "lr = 1e-4"
      ],
      "metadata": {
        "id": "lxdpMD50UsFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we train:"
      ],
      "metadata": {
        "id": "nm4KB-YuUuef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for e in range(num_epochs):\n",
        "    # forward step\n",
        "    x1 = random.randint(0, 1)\n",
        "    x2 = random.randint(0, 1)\n",
        "    xor = x1 ^ x2\n",
        "    y = a * x1 + b * x2 + c\n",
        "    exp_y = math.exp(-y)\n",
        "    pred = 1 / (1 + exp_y)\n",
        "\n",
        "    loss = (xor - 1) * y - math.log(1 + exp_y)\n",
        "    #loss = math.pow(xor - pred, 2)\n",
        "\n",
        "    if e % 100000 == 99999:\n",
        "        print(f\"Loss at epoch {e + 1}: {loss}\")\n",
        "\n",
        "    # gradient calculation\n",
        "    da = (xor - 1 + exp_y / (1 + exp_y)) * x1\n",
        "    db = (xor - 1 + exp_y / (1 + exp_y)) * x2\n",
        "    dc = xor - 1 + exp_y / (1 + exp_y)\n",
        "\n",
        "    a -= lr * da\n",
        "    b -= lr * db\n",
        "    c -= lr * dc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1M3m-KZFUuN1",
        "outputId": "9962f07f-81ee-4127-b4d5-8b0e5fad07fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss at epoch 100000: -1.123947260950331e-05\n",
            "Loss at epoch 200000: -15.161469792340748\n",
            "Loss at epoch 300000: -2.1316282072803006e-14\n",
            "Loss at epoch 400000: -30.157562160683632\n",
            "Loss at epoch 500000: -4.359179683888215e-12\n",
            "Loss at epoch 600000: -2.842170943040401e-14\n",
            "Loss at epoch 700000: -52.63106216046873\n",
            "Loss at epoch 800000: 0.0\n",
            "Loss at epoch 900000: 0.0\n",
            "Loss at epoch 1000000: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a, b, c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDdchNPJUzXS",
        "outputId": "1f33766e-6172-4a65-b3eb-b9cc9256a948"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-26.23662682495234, -23.95919608441167, -51.14066607653695)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's see how well our function does."
      ],
      "metadata": {
        "id": "h_x6DuEPU-fs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = [1, 1, 0, 0]\n",
        "x2 = [1, 0, 1, 0]\n",
        "\n",
        "print(f\"Input 1 | Input 2 | XOR\")\n",
        "print(23 * \"-\")\n",
        "\n",
        "for x, y in zip(x1, x2):\n",
        "    print(f\"{x:7} | {y:7} | {x ^ y:3}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdSYTJrSU86h",
        "outputId": "f75ad659-ce80-45bd-8b70-2a16728f6fe9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input 1 | Input 2 | XOR\n",
            "-----------------------\n",
            "      1 |       1 |   0\n",
            "      1 |       0 |   1\n",
            "      0 |       1 |   1\n",
            "      0 |       0 |   0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"XOR | Prediction\")\n",
        "for x, y in zip(x1, x2):\n",
        "    pred = 1 / (1 + math.exp(x * a + y * b + c))\n",
        "    print(f\"{x ^ y:3} | {pred:10e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvOGy4dqWIQy",
        "outputId": "69c9898f-baa8-4b73-aab2-9bc9ba305b28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XOR | Prediction\n",
            "  0 | 1.000000e+00\n",
            "  1 | 1.000000e+00\n",
            "  1 | 1.000000e+00\n",
            "  0 | 1.000000e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do you notice anything?"
      ],
      "metadata": {
        "id": "-Xt6UYkOVOAD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since that didn't work, we're going to make a slightly more complicated neural network.\n",
        "It'll be a two layer neural network.\n",
        "\n",
        "First, we have to initialize."
      ],
      "metadata": {
        "id": "UUtjztX0W_qH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize(mu=0, sigma=1.0):\n",
        "    layer1 = [random.gauss(mu=mu, sigma=sigma), random.gauss(mu=mu, sigma=sigma),\n",
        "              random.gauss(mu=mu, sigma=sigma), random.gauss(mu=mu, sigma=sigma),\n",
        "              0, 0\n",
        "              ]\n",
        "\n",
        "    layer2 = [random.gauss(mu=mu, sigma=sigma), random.gauss(mu=mu, sigma=sigma), 0]\n",
        "\n",
        "    return layer1, layer2"
      ],
      "metadata": {
        "id": "Vl8HBWGmWRJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer1, layer2 = initialize()"
      ],
      "metadata": {
        "id": "fV4Rl4KtVGjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're going to define a different activation function:"
      ],
      "metadata": {
        "id": "8V_-sUv3XV2b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def relu(x):\n",
        "    return x if x > 0 else 0"
      ],
      "metadata": {
        "id": "DgvQ7J2SXX-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're going to define a helper function that gives us a prediction:"
      ],
      "metadata": {
        "id": "fGuqW2TOXLta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(layer1, layer2, x):\n",
        "    x1, x2 = x\n",
        "    y1 = layer1[0] * x1 + layer1[1] * x2 + layer1[4]\n",
        "    y2 = layer1[2] * x1 + layer1[3] * x2 + layer1[5]\n",
        "\n",
        "    z1 = relu(y1)\n",
        "    z2 = relu(y2)\n",
        "\n",
        "    out = layer2[0] * z1 + layer2[1] * z2 + layer2[2]\n",
        "\n",
        "    return 1 / (1 + math.exp(-1 * out))"
      ],
      "metadata": {
        "id": "SDugZK_IXQK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're going to define a train function."
      ],
      "metadata": {
        "id": "A7UjsasiXPRO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(layer1, layer2, x, actual, lr, eps=1e-4):\n",
        "\n",
        "    x1, x2 = x\n",
        "    y1 = layer1[0] * x1 + layer1[1] * x2 + layer1[4]\n",
        "    y2 = layer1[2] * x1 + layer1[3] * x2 + layer1[5]\n",
        "\n",
        "    z1 = relu(y1)\n",
        "    z2 = relu(y2)\n",
        "\n",
        "    out = layer2[0] * z1 + layer2[1] * z2 + layer2[2]\n",
        "\n",
        "    pred = 1 / (1 + math.exp(-out))\n",
        "\n",
        "    if pred == 1.0:\n",
        "        pred -= eps\n",
        "    #loss = math.pow(actual - pred, 2)\n",
        "\n",
        "    loss = -actual * math.log(pred) - (1 - actual) * math.log(1 - pred)\n",
        "\n",
        "    #dloss = -2 * (actual - pred)\n",
        "    dloss = (pred - actual) #/ (pred * (1 - pred))\n",
        "    #dpred = pred * (1 - pred)\n",
        "\n",
        "    dout1 = layer2[0]\n",
        "    dout2 = layer2[1]\n",
        "\n",
        "    dz1 = 1 if z1 > 0 else 0\n",
        "    dz2 = 1 if z2 > 0 else 0\n",
        "\n",
        "    dy10 = x1\n",
        "    dy11 = x2\n",
        "    dy12 = x1\n",
        "    dy13 = x2\n",
        "\n",
        "    layer2[0] -= lr * dloss * z1 # deleted dpred on all\n",
        "    layer2[1] -= lr * dloss * z2\n",
        "    layer2[2] -= lr * dloss\n",
        "\n",
        "    layer1[0] -= lr * dloss * dout1 * dz1 * dy10\n",
        "    layer1[1] -= lr * dloss * dout1 * dz1 * dy11\n",
        "    layer1[2] -= lr * dloss * dout2 * dz2 * dy12\n",
        "    layer1[3] -= lr * dloss * dout2 * dz2 * dy13\n",
        "    layer1[4] -= lr * dloss * dout1 * dz1\n",
        "    layer1[5] -= lr * dloss * dout2 * dz2\n",
        "\n",
        "    return layer1, layer2, loss"
      ],
      "metadata": {
        "id": "TcF2RJcgXSyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How long we want to train and how far our steps are:"
      ],
      "metadata": {
        "id": "6vAeWPtKXdZN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100_000\n",
        "lr = 1e-1"
      ],
      "metadata": {
        "id": "usQCnN9fXZ2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss = 1\n",
        "running_loss = 0"
      ],
      "metadata": {
        "id": "Gv69LizaXgyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer1, layer2 = initialize()"
      ],
      "metadata": {
        "id": "BNe_xZKfXJaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while test_loss > 0.1:\n",
        "    layer1, layer2 = initialize()\n",
        "\n",
        "    test_loss = 0\n",
        "\n",
        "    for e in range(num_epochs):\n",
        "        # forward step\n",
        "        x1 = random.randint(0, 1)\n",
        "        x2 = random.randint(0, 1)\n",
        "        actual = x1 ^ x2\n",
        "        x = [x1, x2]\n",
        "\n",
        "        layer1, layer2, loss = train(layer1, layer2, x, actual, lr)\n",
        "\n",
        "        running_loss += loss\n",
        "\n",
        "        if e % (num_epochs // 10) == ((num_epochs // 10) - 1):\n",
        "            running_loss /= (num_epochs // 10)\n",
        "            test_loss = running_loss\n",
        "            print(f\"Loss at epoch {e + 1}: {running_loss}\")\n",
        "            running_loss = 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-y81tI0XiVb",
        "outputId": "54ec816c-8fc1-4386-9ab7-3778ab977fd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss at epoch 10000: 0.18150946930839604\n",
            "Loss at epoch 20000: 0.0013468871865798075\n",
            "Loss at epoch 30000: 0.0007358036644605053\n",
            "Loss at epoch 40000: 0.0005092385231366276\n",
            "Loss at epoch 50000: 0.0003915583640164301\n",
            "Loss at epoch 60000: 0.0003078076824204115\n",
            "Loss at epoch 70000: 0.00026158743607763687\n",
            "Loss at epoch 80000: 0.0002224250286844402\n",
            "Loss at epoch 90000: 0.0001957796004063435\n",
            "Loss at epoch 100000: 0.00017479327729565494\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "layer1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hT0qINXFX9G9",
        "outputId": "3118d157-1a79-4b4f-dbc4-f0e44b3763bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4.6799630617102626,\n",
              " 4.679992115182438,\n",
              " 3.5345614024069403,\n",
              " 3.53577051920848,\n",
              " -4.679801342666812,\n",
              " -0.00013595629654433863]"
            ]
          },
          "metadata": {},
          "execution_count": 267
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "layer2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9N0UwqDUX9y3",
        "outputId": "a11f9396-cc92-4189-aeb5-e78942324726"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-7.941923015772793, 4.906560869727129, -7.6254645920139685]"
            ]
          },
          "metadata": {},
          "execution_count": 268
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = [1, 1, 0, 0]\n",
        "x2 = [1, 0, 1, 0]\n",
        "\n",
        "print(f\"x | y | XOR | Prediction\")\n",
        "for x, y in zip(x1, x2):\n",
        "    pred = forward(layer1, layer2, [x, y])\n",
        "    print(f\"{x} | {y} | {x ^ y:3} | {pred:10f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tqA3ffzXvmU",
        "outputId": "40acfbee-e59f-4303-9643-3b22ed42b42e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x | y | XOR | Prediction\n",
            "1 | 1 |   0 |   0.000041\n",
            "1 | 0 |   1 |   0.999940\n",
            "0 | 1 |   1 |   0.999940\n",
            "0 | 0 |   0 |   0.000488\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = [1, 1, 0, 0]\n",
        "x2 = [1, 0, 1, 0]\n",
        "\n",
        "print(f\"XOR | Prediction\")\n",
        "for x, y in zip(x1, x2):\n",
        "    pred = 1 if forward(layer1, layer2, [x, y]) > 0.5 else 0\n",
        "    print(f\"{x ^ y:3} | {pred:10}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8VdWhIXX6B2",
        "outputId": "40959c68-9649-4631-b394-94120e0e1051"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XOR | Prediction\n",
            "  0 |          0\n",
            "  1 |          1\n",
            "  1 |          1\n",
            "  0 |          0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we look at it in PyTorch:"
      ],
      "metadata": {
        "id": "EmToDsSqnRq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = torch.nn.Linear(2, 2)\n",
        "        self.fc2 = torch.nn.Linear(2, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        return F.sigmoid(self.fc2(x))"
      ],
      "metadata": {
        "id": "FhI3kL_wnVEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model()"
      ],
      "metadata": {
        "id": "h2jdh0rboTds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-1, momentum=0.9)"
      ],
      "metadata": {
        "id": "qR0al-Peor4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loss_fn = torch.nn.BCELoss()\n",
        "loss_fn = torch.nn.MSELoss()"
      ],
      "metadata": {
        "id": "uVldnoHlpW65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10_000"
      ],
      "metadata": {
        "id": "JVlJ3_N0pvHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for e in range(num_epochs):\n",
        "    # forward step\n",
        "    x1 = random.randint(0, 1)\n",
        "    x2 = random.randint(0, 1)\n",
        "    actual = torch.tensor([x1 ^ x2], dtype=torch.float)\n",
        "    x = torch.tensor([x1, x2], dtype=torch.float)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    pred = model(x)\n",
        "\n",
        "    loss = loss_fn(pred, actual)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss\n",
        "\n",
        "    if e % (num_epochs // 10) == ((num_epochs // 10) - 1):\n",
        "        running_loss /= (num_epochs // 10)\n",
        "        test_loss = running_loss\n",
        "        print(f\"Loss at epoch {e + 1}: {running_loss}\")\n",
        "        running_loss = 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urBIFiTRkgY9",
        "outputId": "729dcfee-28eb-4dc4-9fb7-0197d5edeeaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss at epoch 1000: 0.16700831055641174\n",
            "Loss at epoch 2000: 0.17107121646404266\n",
            "Loss at epoch 3000: 0.17033977806568146\n",
            "Loss at epoch 4000: 0.17130155861377716\n",
            "Loss at epoch 5000: 0.17885981500148773\n",
            "Loss at epoch 6000: 0.17062394320964813\n",
            "Loss at epoch 7000: 0.16937372088432312\n",
            "Loss at epoch 8000: 0.17570529878139496\n",
            "Loss at epoch 9000: 0.18374231457710266\n",
            "Loss at epoch 10000: 0.1696285754442215\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = [1, 1, 0, 0]\n",
        "x2 = [1, 0, 1, 0]\n",
        "\n",
        "print(f\"x | y | XOR | Prediction\")\n",
        "for x, y in zip(x1, x2):\n",
        "    pred = model(torch.tensor([x, y], dtype=torch.float))\n",
        "    print(f\"{x} | {y} | {x ^ y:3} | {pred.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJK3uSUwpiNq",
        "outputId": "0d537484-5528-46ed-8b9d-5d36f63461ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x | y | XOR | Prediction\n",
            "1 | 1 |   0 | 0.4025195837020874\n",
            "1 | 0 |   1 | 0.9999997615814209\n",
            "0 | 1 |   1 | 0.4025195837020874\n",
            "0 | 0 |   0 | 0.4025195837020874\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(model.fc1.parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8vEw6pcp-2g",
        "outputId": "1ec8f099-b4cf-41e3-c5ae-14e5fdd94980"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[-0.2303,  0.0951],\n",
              "         [ 3.5690, -3.5791]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-0.5658, -0.0024], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 395
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(model.fc2.parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccEN8SHEqjZy",
        "outputId": "a1dd1f49-76a3-4936-b99a-50ad05f04fad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[0.3763, 4.4470]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-1.7391], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 391
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = [1, 1, 0, 0]\n",
        "x2 = [1, 0, 1, 0]\n",
        "\n",
        "print(f\"XOR | Prediction\")\n",
        "for x, y in zip(x1, x2):\n",
        "    pred = 1 if model(torch.tensor([x, y], dtype=torch.float)).item() > 0.5 else 0\n",
        "    print(f\"{x ^ y:3} | {pred:10}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88oVF7s0qq0j",
        "outputId": "ef1d0a59-5d5e-4c8e-f4f1-de5087f75cb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XOR | Prediction\n",
            "  0 |          0\n",
            "  1 |          1\n",
            "  1 |          0\n",
            "  0 |          0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jgT9R9-vroBA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}