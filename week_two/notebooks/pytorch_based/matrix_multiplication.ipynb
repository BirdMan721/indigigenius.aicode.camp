{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "059b31ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "477987fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pprint\n",
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bce492",
   "metadata": {},
   "source": [
    "We're going to work on matrix multiplication today.\n",
    "Matrices and multi-dimensional arrays are essential to scientific computing and to neural networks in particular.\n",
    "Neural networks, for the most part, are just a series of matrix multiplications and vector operations.\n",
    "So, it's essential that you learn about these!\n",
    "\n",
    "The primary framework for matrix operations is the BLAS (basic linear algebra subprograms) and these are the actual implementations used in scientific computing.\n",
    "Today, we're going to build our own:\n",
    "- vector class\n",
    "- matrix class\n",
    "- **dot product**\n",
    "- **saxpy** function (level 1 BLAS)\n",
    "- **gaxpy** function (level 2 BLAS)\n",
    "- **level 3** BLAS function\n",
    "\n",
    "We're then going to work on understanding:\n",
    "- the `ndarray` class in numpy\n",
    "- the `tensor` class in pytorch\n",
    "- the stride method in `tensor`\n",
    "\n",
    "After this, we're going to move onto working with these in the numpy and pytorch libraries.\n",
    "We'll see that numpy is faster than our implementations (they are heavily optimized by thousands of researchers and developers over many years).\n",
    "It's still important to understand what is happening under the hood!\n",
    "\n",
    "Let's look at vectors first!\n",
    "A vector is just a sequence of numbers.\n",
    "For example:\n",
    "$$\n",
    "(1, 3, 5)\n",
    "$$\n",
    "is a 3-dimensional vector!\n",
    "It can be arbitrarily long, so we can have a $1,000,000$-dimensional vector.\n",
    "\n",
    "We've already seen a python class that works just like a vector.\n",
    "Do you know what it is?\n",
    "\n",
    "Let's use these to build our vector class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56031afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vector():\n",
    "    \n",
    "    def __init__(self, values):\n",
    "        # This should have an input.\n",
    "        # What do we need to input to create a vector?\n",
    "        self.num_values = len(values)\n",
    "        self.values = tuple(values)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.values[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.values)\n",
    "    \n",
    "    def __add__(self, other):\n",
    "        if self.num_values != other.num_values:\n",
    "            raise Exception(f\"Dimension mismatch: {self.num_values} != {other.num_values}\")\n",
    "            \n",
    "        add = []\n",
    "        for num in range(self.num_values):\n",
    "            add.append(self.values[num] + other.values[num])\n",
    "        return Vector(add)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Vector({self.values})\"\n",
    "    \n",
    "    def __str__(self):\n",
    "        vec_string = ''\n",
    "        for num in range(self.num_values):\n",
    "            vec_string = vec_string + str(self.values[num])\n",
    "        return vec_string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cc9f13",
   "metadata": {},
   "source": [
    "One reason we might want to build our own class rather than use the python classes that look like vectors is readability.\n",
    "Tuples and lists are general classes and can be used for anything.\n",
    "Whereas if we create a Vector class, then that tells anyone who is working on our code that these represents vectors.\n",
    "This means that they wouldn't do something that isn't allowed in vector operations.\n",
    "For example, they would know our `Vector` class should not have an `append` method, like `list` has.\n",
    "\n",
    "We're going to talk about the dot product function and then try to implement it.\n",
    "If we have two vectors of the same dimension, $\\textbf{x} = (x_{1}, \\ldots, x_{n})$ and $\\textbf{y} = (y_{1}, \\ldots, y_{n})$, then\n",
    "$$\n",
    "\\textbf{x} \\cdot \\textbf{y} = x_{1}y_{1} + x_{2}y_{2} + \\cdots + x_{n}y_{n} = \\sum_{i = 1}^{n} x_{i}y_{i}.\n",
    "$$\n",
    "We just multiply the elements together and then sum them!\n",
    "This gives us a chance to practice our `for` loops!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e50f3c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Vector((1, 2, 3))\n",
    "x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "581409b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_product(vector1, vector2):\n",
    "    # We need to initialize a value\n",
    "    dot = 0\n",
    "    \n",
    "    # We need to do a for loop\n",
    "    for num in range(vector1.num_values):\n",
    "        dot += vector1[num] * vector2[num]\n",
    "        \n",
    "    return dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02c9c2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n"
     ]
    }
   ],
   "source": [
    "x = Vector((1, 3, 5))\n",
    "y = Vector((2, 4, 6))\n",
    "\n",
    "print(dot_product(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51673ab4",
   "metadata": {},
   "source": [
    "Another bit of `for` loops practice is programming `saxpy`.\n",
    "What `saxpy` stands for is single precision $a$ times $\\textbf{x}$ plus $\\textbf{y}$.\n",
    "\n",
    "The inputs are a scalar $a$ and two vectors of the same dimension: $\\textbf{x}$ and $\\textbf{y}$.\n",
    "The output should be a vector.\n",
    "The implementation is:\n",
    "$$\n",
    "a \\textbf{x} + \\textbf{y} = a \\cdot(x_{1}, \\ldots, x_{n}) + (y_{1}, \\ldots, y_{n}) = (ax_{1} + y_{1}, \\ldots, ax_{n} + y_{n})\n",
    "$$\n",
    "Let's implement this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5357dcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saxpy(a, x, y):\n",
    "    # a: a float\n",
    "    # x: a Vector of floats\n",
    "    # y: a Vector of floats\n",
    "    # output: a vector of floats\n",
    "    val = [None for i in range(y.num_values)]\n",
    "    \n",
    "    for num in range(x.num_values):\n",
    "        val[num] = a * x[num] + y[num]\n",
    "    \n",
    "    return Vector(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ca90de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vector((5, 13, 21))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saxpy(3, Vector((1, 3, 5)), Vector((2, 4, 6)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4dd4b3",
   "metadata": {},
   "source": [
    "Now we're going to implement talk about what a matrix is, then we're going to make a matrix class!\n",
    "A matrix is an array of arrays or a collection of vectors.\n",
    "We just have to note that these arrays should have the same length or if we think of them as a collection of vectors, these vectors have to have the same dimension.\n",
    "\n",
    "Here's an example of a matrix:\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "1 & 2 & 3 \\\\\n",
    "4 & 5 & 6\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "or\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "1 & 0 & 0 \\\\\n",
    "0 & 1 & 0 \\\\\n",
    "0 & 0 & 1\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "We denote a matrix by $n \\times m$, where $n$ is the number of rows and $m$ is the number of columns.\n",
    "\n",
    "Another way to write a matrix is\n",
    "$$\n",
    "\\textbf{A} = (a_{ij})_{ij}.\n",
    "$$\n",
    "This tells us the $i$th row and the $j$th column is the value $a_{ij}$.\n",
    "It's a useful method of representing the matrix abstractly.\n",
    "\n",
    "Another thing to know about is the transpose of the matrix.\n",
    "This will be useful shortly.\n",
    "If\n",
    "$$\n",
    "\\textbf{A} = (a_{ij})_{ij}.\n",
    "$$\n",
    "then the transpose of $\\textbf{A}$ is denoted by $\\textbf{A}^{\\intercal}$ and\n",
    "$$\n",
    "\\textbf{A}^{\\intercal} = (a_{ji})_{ij}.\n",
    "$$\n",
    "The columns become the rows and the rows become the columns.\n",
    "\n",
    "Let's make a matrix class!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7100cddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Matrix():\n",
    "    \n",
    "    def __init__(self, values):\n",
    "        # We need to define several class variables, rows, columns, and the matrix values.\\\n",
    "        self.rows = len(values)\n",
    "        self.cols = len(values[0])\n",
    "        self.values = self._create_matrix(values)\n",
    "        \n",
    "    def _create_matrix(self, values):\n",
    "        num_cols = len(values[0])\n",
    "        num_rows = len(values)\n",
    "        \n",
    "        for num in range(num_rows):\n",
    "            if len(values[num]) != num_cols:\n",
    "                raise Exception(f\"Dimension mismatch: {len(num)} != {num_cols}\")\n",
    "        \n",
    "        for num in range(num_rows):\n",
    "            values[num] = list(values[num])\n",
    "            \n",
    "        return list(values)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        # This needs to return a string that tells you the class and some values.\n",
    "        # Another way to think about it is that you need to give someone the right amount of\n",
    "        # information to understand this class.\n",
    "        return f\"Matrix({self.values})\"\n",
    "\n",
    "    def __getitem__(self, i, j=None):\n",
    "        # i is the row you want to access and j is the column you want to access.\n",
    "        # Reference the vector class above.\n",
    "        return self.values[i][j] if j else self.values[i]\n",
    "\n",
    "    def __len__(self):\n",
    "        # This should return an integer.\n",
    "        return len(self.values)\n",
    "    \n",
    "    def __str__(self):\n",
    "        # This should return a string that makes the elements easy to read.\n",
    "        matrix_string = '['\n",
    "        for rows in range(self.rows):\n",
    "            matrix_string += '['\n",
    "            for cols in range(self.cols):\n",
    "                matrix_string += str(self.values[rows][cols]) + ', '\n",
    "            matrix_string = matrix_string[:-2] + ']\\n '\n",
    "        matrix_string = matrix_string[:-2] + ']'\n",
    "        return matrix_string\n",
    "\n",
    "    def transpose(self):       \n",
    "        # Initialize\n",
    "        transpose = [[0 for i in range(self.rows)] for i in range(self.cols)]\n",
    "\n",
    "        # Set the values\n",
    "        for row in range(self.rows):\n",
    "            for col in range(self.cols):\n",
    "                transpose[col][row] = self.values[row][col]\n",
    "\n",
    "        return Matrix(transpose)\n",
    "    \n",
    "    def __add__(self, other):\n",
    "        if not(self.rows == other.rows and self.cols == other.cols):\n",
    "            raise Exception(\"The rows or columns do not match.\")\n",
    "        \n",
    "        add = [[None for i in range(self.cols)] for j in range(self.rows)]\n",
    "        \n",
    "        for row in range(self.rows):\n",
    "            for col in range(self.cols):\n",
    "                add[row][col] = self.values[row][col] + other.values[row][col]\n",
    "                \n",
    "        return Matrix(add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "630c45b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3]\n",
      " [4, 5, 6]]\n",
      "[[3, 6, 9]\n",
      " [12, 15, 18]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Matrix([[1, 2, 3], [4, 5, 6]])\n",
    "y = Matrix([[2, 4, 6], [8, 10, 12]])\n",
    "print(x)\n",
    "\n",
    "print(x + y)\n",
    "\n",
    "x[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089eb8a8",
   "metadata": {},
   "source": [
    "We're going to talk about matrix vector multiplications.\n",
    "\n",
    "**Matrix Vector Multiplication**\n",
    "\n",
    "If our input is an $n \\times m$ matrix $\\textbf{A} = (a_{ij})_{ij}$ and an $m$-dimensional vector $\\textbf{x} = (x_{1}, \\ldots, x_{m})$, then our output is an $n$-dimensional vector.\n",
    "$$\n",
    "\\textbf{A} \\cdot \\textbf{x} = \\left(\\sum_{i=1}^{m} a_{i1}x_{i}, \\ldots, \\sum_{i=1}^{m} a_{in}x_{i}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af6d995b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mat_vec_mul(matrix, vector):\n",
    "    # Our input is a matrix and a vector\n",
    "    # Our output is a vector\n",
    "    out = [0 for i in range(matrix.rows)]\n",
    "\n",
    "    for row in range(matrix.rows):\n",
    "        print(transpose[row])\n",
    "        out[row] = dot_product(Vector(matrix[row]), vector)\n",
    "        \n",
    "#        for col in range(matrix.cols):\n",
    "#            out[row] += matrix[row][col] * vector[col]\n",
    "\n",
    "    return Vector(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8e0fd315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 4]\n",
      " [2, 5]\n",
      " [3, 6]]\n",
      "[1, 4]\n",
      "[2, 5]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Vector((14, 32))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Matrix([[1, 2, 3], [4, 5, 6]])\n",
    "y = Vector([1, 2, 3])\n",
    "\n",
    "\n",
    "# [14, 32]\n",
    "mat_vec_mul(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db490244",
   "metadata": {},
   "source": [
    "Now, we're going to talk about matrix multiplication.\n",
    "\n",
    "**Matrix Multiplication**\n",
    "\n",
    "If we have two matrices, $\\textbf{A} = (a_{ij})_{ij}$, an $n \\times m$ matrix, and $\\textbf{B} = (b_{ij})_{ij}$, an $m \\times p$ matrix. \n",
    "Note, we cannot multiply matrices unless the number of columns in the first matrix is the same as the number of rows in the second matrix!\n",
    "The output is a matrix of size $n \\times p$ and the values of the matrix are:\n",
    "$$\n",
    "\\textbf{A} \\cdot \\textbf{B} = (\\sum_{k = 1}^{m} a_{ik}b_{kj})_{ij}\n",
    "$$\n",
    "\n",
    "Another way to think about it is that matrix multiplication comes from the dot products of the rows of the first matrix with the columns of the second matrix.\n",
    "The dot product method is why we implemented the transpose method of the `Matrix` class.\n",
    "\n",
    "We can also do matrix multiplication with a series of matrix vector operations.\n",
    "The columns of the new matrix come from the multiplication of the matrix $\\textbf{A}$ with the column vectors.\n",
    "\n",
    "So, you have a number of different ways to think about matrix multiplication and implement it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d9fbf10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_mult(matrix1, matrix2):\n",
    "    # The inputs are two matrices.\n",
    "    # The output is a matrix.\n",
    "    if matrix1.cols != matrix2.rows:\n",
    "        raise Exception(f\"Dimension mismatch! Rows should equal columns, but {matrix1.cols} != {matrix2.rows}\")\n",
    "    \n",
    "    out = [[0 for i in range(matrix2.cols)] for j in range(matrix1.rows)]\n",
    "    \n",
    "    for row in range(matrix1.rows):\n",
    "        for col in range(matrix2.cols):\n",
    "            for k in range(matrix1.cols):\n",
    "                out[row][col] += matrix1[row][k] * matrix2[k][col]\n",
    "    \n",
    "    return Matrix(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "116e241b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22, 28]\n",
      " [49, 64]]\n"
     ]
    }
   ],
   "source": [
    "A = Matrix([[1, 2, 3], [4, 5, 6]])\n",
    "B = Matrix([[1, 2], [3, 4], [5, 6]])\n",
    "\n",
    "C = matrix_mult(A, B)\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9d4eda",
   "metadata": {},
   "source": [
    "We're going to talk about the numpy and pytorch libraries and if we have time, we're going to go back to the BLAS functions!\n",
    "\n",
    "The numpy `ndarray` class and the pytorch `Tensor` class operate similarly.\n",
    "We're going to just call these tensors from now on.\n",
    "How we can think of these is that they are an array of an array of an array of arrays, etc.\n",
    "So, a vector is an array of numbers.\n",
    "A matrix is an array of an array of numbers.\n",
    "We can have an array of matrices, which is an array of an array of an array of numbers.\n",
    "We can keep going.\n",
    "\n",
    "The **shape** of a tensor is the dimensions.\n",
    "For an $n$-dimensional vector, it has shape $(n, )$.\n",
    "For an $n\\times m$ matrix, it has shape $(n, m)$.\n",
    "For a collection of $p$ $n\\times m$ matrices would have shape $(p, n, m)$.\n",
    "\n",
    "The primary example we're going to have is images.\n",
    "A black and white image can be represented by a matrix, where the values of the matrix correspond to pixels.\n",
    "So, if we had an image of height 224 pixels and width 224 pixels, the matrix would be a $224 \\times 224$ matrix and have shape $(224, 224)$.\n",
    "Typically, the height is the number of rows and the width is the number of columns in the matrix.\n",
    "\n",
    "A color image can be represented by 3 matrices, **rgb**, which stands for red green blue.\n",
    "There is a matrix that corresponds to the red values, a matrix that corresponds to the blue values, and a matrix that corresponds to the green values.\n",
    "Each of these matrices would have shape $(224, 224)$ and the collection of the matrices would have shape $(3, 224, 224)$.\n",
    "Typically, we call the number 3 above the **channels**.\n",
    "\n",
    "If we have a collection of color images, say 16, then that could be represented as a tensor of shape $(16, 3, 224, 224)$.\n",
    "\n",
    "There are several ways to make an `ndarray` or `tensor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "646081b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1, 2, 3], [4, 5, 6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "fc2852b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6]])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "ee1620d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tensor = torch.tensor([[1, 2, 3], [4, 5, 6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "f4d0215c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "ef0856de",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tensor = torch.tensor(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "a536ff02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "4005893e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_numpy = x_tensor.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "82d29c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6]])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61902247",
   "metadata": {},
   "source": [
    "We can get the shape from the `ndarray` and `tensor` by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "f342da1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n",
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(x_numpy.shape)\n",
    "print(x_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5fc014",
   "metadata": {},
   "source": [
    "An important thing to know is that all `ndarrays` and `tensors` are stored as an array of shape $(n, )$.\n",
    "If we have a `tensor` of shape $(16, 3, 224, 224)$, then it's stored as an array of $16 \\times 3 \\times 224 \\times 224 = 2,408,448$ values.\n",
    "How the `tensor` transforms this data is by what are called **strides**.\n",
    "The stride tells us how to skip over the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "7e7b80aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 8)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_numpy.strides"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99359b47",
   "metadata": {},
   "source": [
    "The layout of `x_numpy` is $[1, 2, 3, 4, 5, 6]$.\n",
    "Each of these values in the array occupy 8 bytes.\n",
    "If we want to get element $4$, we would have to go $24 + 8$ bytes into our array.\n",
    "\n",
    "It should be noted that the numpy strides are based on bytes!\n",
    "In numpy, ints are 64 bit by default, so they cover 8 bytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "8e74affd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_numpy[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7764fdcf",
   "metadata": {},
   "source": [
    "I prefer the way pytorch gives us the strides.\n",
    "It abstracts away the size of our objects in memory and just treats it like an array of arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "9c2ba4c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tensor.stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71818730",
   "metadata": {},
   "source": [
    "The layout of `x_tensor` is the same as `x_numpy`.\n",
    "If we want to access the element in row $i$ and column $j$, we select the $3 * i + j$th element in our array.\n",
    "\n",
    "If we have a tensor of shape $(16, 3, 28, 28)$, a collection of 16 color images with height and width of 28 pixels.\n",
    "The stride will be $(3 \\times 28 \\times 28, 28 \\times 28, 28, 1) = (2352, 784, 28, 1)$.\n",
    "So, if we want to access the pixel at (5, 1, 15, 13), we call `images[4][0][14][12]`.\n",
    "Under the hood, the tensor is calling `images[4 * 2352 + 0 * 784 + 28 * 14 + 1 * 12]` or `images[9812]`.\n",
    "\n",
    "Now, we're going to look at how to do our operations above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "d67f0f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor1 = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "tensor2 = torch.tensor([[1, 2], [3, 4], [5, 6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "ab37d625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[22, 28],\n",
       "        [49, 64]])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(tensor1, tensor2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6017817",
   "metadata": {},
   "source": [
    "If we want to do matrix vector multiplication we do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "a33411cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "vector = torch.tensor([1, 5, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "373b3ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([20, 47, 74])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mv(matrix, vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1df9a8",
   "metadata": {},
   "source": [
    "The dot product is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "ffeb0dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector1 = torch.tensor([1, 5, 3])\n",
    "vector2 = torch.tensor([2, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "443408f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(13)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dot(vector1, vector2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d25003",
   "metadata": {},
   "source": [
    "Finally, one important concept to know about is broadcasting.\n",
    "Broadcasting allows us to add or multiply a matrix and a vector together or in general any `tensor` with any `tensor` as long as a few rules are followed:\n",
    "\n",
    "**Broadcasting rules**\n",
    "\n",
    "These rules are determined by the shape:\n",
    "the rightmost elements of the shape are the same or one of them is 1, then proceeds to the left.\n",
    "\n",
    "So, we can add a $(28, )$-tensor to a $(16, 3, 28, 28)$-tensor.\n",
    "We can add a $(3, 1, 28)$-tensor to a $(16, 3, 28, 28)$-tensor.\n",
    "We can add a $(3, 28, 28)$-tensor to a $(16, 3, 28, 28)$-tensor.\n",
    "Or even a $(3, 4, 1)$-tensor to a $(3, 1, 5)$-tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "50089b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_broadcastable(shape1, shape2):\n",
    "    \n",
    "    # Initialization\n",
    "    broadcast = False\n",
    "    \n",
    "    # We need to only check over the smallest shape.\n",
    "    min_length = min(len(shape1), len(shape2))\n",
    "    \n",
    "    # We start at the end.\n",
    "    shape1 = list(reversed(shape1))\n",
    "    shape2 = list(reversed(shape2))\n",
    "    \n",
    "    # We only keep the necessary elements.\n",
    "    shape1 = shape1[:min_length]\n",
    "    shape2 = shape2[:min_length]\n",
    "\n",
    "    # zip combines shape1 and shape2\n",
    "    for x, y in zip(shape1, shape2):\n",
    "        # We check that the shapes are the same or one of them is 1.\n",
    "        if (x == y) or (x == 1) or (y == 1):\n",
    "            broadcast = True\n",
    "        else:\n",
    "            # If the above condition ever fails, the tensors are not broadcastable.\n",
    "            return False\n",
    "    \n",
    "    return broadcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "a328e47f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_broadcastable((8, 1, 6, 1), (7, 1, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c4f8b3",
   "metadata": {},
   "source": [
    "As an exercise, try to implement the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "66b663c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaxpy(a, b, mat, x_vector, y_vector):\n",
    "    # Given two scalars a and b, a matrix mat, and two vectors x_vector and y_vector\n",
    "    # return a vector the same size as y_vector that has the value\n",
    "    # a * A * x + b * y\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "8b2de50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def level3_blas(a, b, A, B, C):\n",
    "    # Given two scalars a and b and three matrices, A, B, C\n",
    "    # return a mtrix the same size as C that has the value\n",
    "    # a * A * B + b * C\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a758e6ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
